\documentclass[12pt]{article}
\usepackage[usenames]{color} %used for font color
\usepackage{amsmath, amssymb, amsthm}
\usepackage{wasysym}
\usepackage[utf8]{inputenc} %useful to type directly diacritic characters
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{mathtools}
\usepackage [english]{babel}
\usepackage [autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
\graphicspath{ {./} }
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\prob}{\mathbb{P}}
\newcommand{\degrees}{^{\circ}}
\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

\author{Tianshuang (Ethan) Qiu}
\begin{document}
\title{Math 104, HW5}
\maketitle
\newpage

\section{Ross 14.1}
\subsubsection{a}
For this we will use the limit comparison test. $n^4 < (3/2)^n$ for large $n$, so let us only consider $n>100$. Now we know that $\sum (\frac{1.5}{2})^n$ converges due to geometric series identity.
\newline
$\sum \frac{n^4}{2^n} < \sum (\frac{1.5}{2})^n$ for large $n$, and since tha latter converges, the former converges as well. Q.E.D.

\subsection{b}
For this we will use the limit comparison test. $3^n < n!$ for large $n$, so let us only consider $n>10$. We know that $\sum (\frac{2}{3})^n$ converges due to geometric series identity.
\newline
$\sum \frac{2^n}{n!} < \sum (\frac{2}{3})^n$ for large $n$, since a larger denominator means a smaller value. Since tha latter converges, the former converges as well. Q.E.D.

\subsection{c}
For this we will use the limit comparison test. $n^2 < 2^n$ for $n>2$. We know that $\sum (\frac{2}{3})^n$ converges due to geometric series identity.
\newline
$\sum \frac{n^2}{3^n} < \sum (\frac{2}{3})^n$ for large $n$. Since tha latter converges, the former converges as well. Q.E.D.

\subsection{d}
We apply the ratio test to $\sum \frac{n!}{n^4}$:
$$\lim \sup |\frac{(n+1)!}{(n+1)^4}\frac{n^4}{n!}| = n+1 > 1$$
Therefore it does not converge by ratio test.

\subsection{e}
Since $cos^2n \leq 1, \sum \frac{cos^2n}{n^2} \leq \sum \frac{1}{n^2}$
\newline
Now we apply the root test to $\frac{1}{n^2}$:
$$|\frac{1}{n^2}|^{1/n} \leq 1^{1/n} = 1$$
Therefore $\sum \frac{1}{n^2}$ converges by root test, and $\sum \frac{cos^2n}{n^2}$ converges by limit comparison.

\subsection{f}
We compare this to $\sum \frac{1}{n}$ where $n \geq 2$. $\log n < n$, so $1/\log n < 1/ n$. Since we know that $\sum \frac{1}{n}$ is the harmonic series and does not converge, $\sum \frac{1}{\log n}$ also does not converge by limit comparison.
\newpage


\section{Ross 14.12}
Since $\lim \inf |a_n|=0$, for all $\epsilon > 0$, there exists $|a_n|\leq \epsilon$.
\newline
Pick our subsequence $b_1$ to be $a_1$, and $b_2$ to be $a_n s.t. |a_n|\leq\frac{|b-1|}{2}$. We can continue like this, defining $b_n$ recursively:
$$b_n = a_k s.t. |a_k|<|b_{n-1}|/2$$
We know that we can always find such an $a_k$ because the limit inferior is 0, so $a_n$ must be able to get arbitrarily close to 0.
\newline
Since we have picked each element in our series to be less than or equal to half of the former, it is less than or equal to the geometric sum $a_1(\frac{1}{2})^n$. The geometric series converges, and so does our series by limit comparison test.
Q.E.D.
\newpage

\section{Ross 14.14}
Let the harmonic series be named $h_n$ and the provided series be $a_n$.
\newline
From what was given, we can provide a formula for $a_n$: $$a_n = \frac{1}{2^{\floor*{\frac{n}{2}}}}$$
\newline
Since $2^{\floor*{\frac{n}{2}}}$ will always be at least 1 greater than $n$, we have $h_n > a_n$
\newline
Now we attempt to show that $a_n$ does not converge. We can the similar terms together, it is simple to see that it sums to $\frac{1}{2}$. We can further prove this using our formula for $a_n$: for any $a_n = \frac{1}{2^k}$, there are $2^{k-1}$ terms of such $a_n$, which sums to
$$2^{k-1}\frac{1}{2^k} = \frac{1}{2}$$
We see that sum any $a_n$ with like terms to get $\frac{1}{2}$, so we state that $\sum_{n=2}^\infty a_n = \sum_{n=2}^\infty \frac{1}{2}$
\newline
This series does not converge because the limit is not 0. Therefore $\frac{1}{n}$ also does not converge by limit comparison test.
\newpage


\section{Ross 15.3}
If $p\leq0$, we can simply apply the limit comparison test to see that it is greater than or equal to the harmonic series, which does not converge, implying that the series also does not converge.
\newline
Now for $p \geq 1$, we apply the integral test.
$$\int_{2}^{\infty}\frac{1}{n(\log n)^p}) \,dn = \lim _{n \to \infty} \int_{2}^{n}\frac{1}{n(\log n)^p} \,dn$$
(Assuming that log means the natural log) Let $u = \ln n, du = \frac{1}{n}$
$$= \lim _{n \to \infty} \int_{\ln 2}^{\ln n} \frac{1}{u^p} \,du$$
This integral can be evaluated to a finite value for $p>1$ because we can use the power rule. When $p = 1$, the integral evaluates to $\ln u$, which is not finite when $u \to \infty$.
\newline
Q.E.D.
\newpage


\section{Q5}
\subsection{a}
Let $\epsilon > 0, x_0 \in \R$. We pick $\delta = \min \{1, \frac{\epsilon}{1+2|x_0|}\}$
\newline
Let $|x-x_0|<\delta$, Consider $|f(x)-f(x_0)| = |x^2-x_0^2| = |x+x_0||x-x_0|$. By our definition of $\delta$, the expression is strictly less than $|x+x_0|\delta$
\newline
Now we examine our definition of $\delta$. Since it cannot be greater than 1, we have $|x-x_0|<1$. By algebraic manipulation we can state that $|x+x_0|=|x-x_0+2x_0|$, and apply the triangle inequality: $|x+x_0|\leq |x-x_0|+|2x_0|$
\newline
We can now subsitute in $1$ to get $|x+x_0|\leq 1+|2x_0|$
\newline
Now we connect it all together:
$$|f(x)-f(x_0)| = |x^2-x_0^2| < (1+|2x_0|)\delta = \epsilon$$
Thus we have proven that it is continuous.
\newline
Q.E.D.

\subsection{b}
Let $\epsilon > 0, x_0 \in \R$. We pick $\delta = \min \{1, \frac{\epsilon}{(1+|x_0|)^2+|x_0+|x_0|^2|+|x_0^2|} \}$
\newline
Let $|x-x_0|<\delta$, Consider $|f(x)-f(x_0)| = |x^3-x_0^3| = |x-x_0||x^2+xx_0+x_0^2|$. By our definition of $\delta$, the expression is strictly less than $|x^2+xx_0+x_0^2|\delta \leq (|x|^2+|xx_0|+|x_0^2|)\delta$
\newline
Now we examine our definition of $\delta$. Since it cannot be greater than 1, we have $|x-x_0|<1$. By the triangle inequality we can state that $|x|< 1+|x_0|$.
\newline
We can now subsitute $|x|$:
$$|f(x)-f(x_0)| \leq (|x|^2+|xx_0|+|x_0^2|)\delta <((1+|x_0|)^2+|x_0+|x_0|^2|+|x_0^2|)\delta = \epsilon$$
Thus we have proven that it is continuous.
\newline
Q.E.D.
\newpage


\section{Q6}
\subsection{If x = 0}
Let $\epsilon > 0, x_0 = 0$. We pick $\delta = \epsilon^2$
\newline
Let $|x-x_0|<\delta$, we have $|f(x)-f(x_0)| = |\sqrt x - 0| = \sqrt x$ since $\sqrt 0 = 0$, and the result of a square root is always non-negative.
\newline
Since we have defined $\delta$, $|x-x_0|<\delta \implies x < \delta \implies f(x) < \sqrt \delta = \epsilon$
\newline
Thus we have proved that the function is continuous at $x=0$.

\subsection{If x $> $0}
Let $\epsilon > 0, x_0 \in \R^+$. We pick $\delta = \min \{1, \frac{|\sqrt{1+|x_0|} + \sqrt x_0|}{\epsilon}\}$
\newline
Let $|x-x_0|<\delta$, Consider $|f(x)-f(x_0)| = |\sqrt x - \sqrt x_0| = |\sqrt x - \sqrt x_0| \frac{|\sqrt x + \sqrt x_0|}{|\sqrt x + \sqrt x_0|} = |\frac{x-x_0}{|\sqrt x + \sqrt x_0|}| = |\frac{x-x_0}{|\sqrt |x| + \sqrt x_0|}|$
\newline
Now we examine our definition of $\delta$. Since it cannot be greater than 1, we have $|x-x_0|<1$. By the triangle inequality we can state that $|x|< 1+|x_0|$.
\newline
We can now subsitute $|x|, \delta$:
$$|f(x)-f(x_0)| = |\frac{x-x_0}{|\sqrt {|x|} + \sqrt x_0|}| <  |\frac{\delta}{|\sqrt{1+|x_0|} + \sqrt{x_0|}}|= \epsilon$$
Thus we have proven that it is continuous.
\newline
Q.E.D.
\newpage


\section{Ross 17.10}
\subsection{a}
Let $x_0 = 0, \epsilon = 0.5$. Let $\delta > 0$, choose $x = \delta/2$. This fulfills the requirement that $|x-x_0|<\delta$. Now since $x>0$, $f(x) = 1$. However we know that $f(x)=f(0)=0$, $|f(x)-f(x_0)|=1  > \epsilon$
\newline
Thus we have shown that when $\epsilon = 0.5$, we cannot find a small enough delta to fulfill the property of continuity, there will always be a "big jump" to the right. Therefore the function is not continuous.

\subsection{b}
We first observe the sine function, for any $x$, between $[x, x+2\pi]$, the function will yield a $1$ and a $-1$ since it is cyclical.
\newline
Let $x_0 = 0, \epsilon = 0.01$. Let $\delta > 0$, choose $x = \min\{\delta/2, 1\}$. This fulfills the requirement that $|x-x_0|<\delta$. If $|f(x)|>0.01$, the proof is complete since this violates the epsilon delta property.
\newline
Otherwise we attempt to make $x$ smaller to violate the property. Since $0<x<1$, making $x$ smaller will make $1/x$ bigger. Consider the interval $$\frac{1}{x}<\frac{1}{x'}<\frac{1}{x}+2\pi$$
$$0<\frac{x}{1+2\pi x}<x'<x$$
This interval must yield a $1$ since $1/x$ has changed by $2\pi$, so let this value be denoted by $x', f(x')=1$. Since $x'$ is less than $x$, it is still within $\delta$ of 0. Therefore we have found a value inside our delta such that $|f(x')-f(x)|=0.99>\epsilon$
\newline
This violates the epsilon delta property, and the function is not continuous. Q.E.D.

\subsection{c}
Let $x_0 = 0, \epsilon = 0.5$. Let $\delta > 0$, choose $x = \delta/2$. This fulfills the requirement that $|x-x_0|<\delta$. Now since $x>0$, $f(x) = 1$. However we know that $f(x)=f(0)=0$, $|f(x)-f(x_0)|=1  > \epsilon$
\newline
We can then repeat this process with $x' = -\delta/2$, with $f(x')=-1, |f(x')-f(x)|=1>\epsilon$
\newline
Thus we have shown that when $\epsilon = 0.5$, we cannot find a small enough delta to fulfill the property of continuity, there will always be a "big jump" to the left and to the right. Therefore the function is not continuous.

\end{document}
